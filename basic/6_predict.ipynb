{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ef7f83",
   "metadata": {},
   "source": [
    "# Level 6: Predict with your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9e336",
   "metadata": {},
   "source": [
    "## Saving and loading checkpoints (basic)\n",
    "When a model is training, the performance changes as it continues to see more data. It is a best practice to save the state of a model throughout the training process. This gives you a version of the model, a checkpoint, at each key point during the development of the model. Once training has completed, use the checkpoint that corresponds to the best performance you found during the training process.\n",
    "\n",
    "Checkpoints also enable your training to resume from where it was in case the training process is interrupted.\n",
    "\n",
    "PyTorch Lightning checkpoints are fully usable in plain PyTorch.\n",
    "\n",
    "Contents of a checkpoint\n",
    "A Lightning checkpoint contains a dump of the model’s entire internal state. Unlike plain PyTorch, Lightning saves everything you need to restore a model even in the most complex distributed training environments.\n",
    "\n",
    "Inside a Lightning checkpoint you’ll find:\n",
    "\n",
    "- 16-bit scaling factor (if using 16-bit precision training)\n",
    "\n",
    "- Current epoch\n",
    "\n",
    "- Global step\n",
    "\n",
    "- LightningModule’s state_dict\n",
    "\n",
    "- State of all optimizers\n",
    "\n",
    "- State of all learning rate schedulers\n",
    "\n",
    "- State of all callbacks (for stateful callbacks)\n",
    "\n",
    "- State of datamodule (for stateful datamodules)\n",
    "\n",
    "- The hyperparameters (init arguments) with which the model was created\n",
    "\n",
    "- The hyperparameters (init arguments) with which the datamodule was created\n",
    "\n",
    "- State of Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3f63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lightning import LightningModule\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f980ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets\n",
    "transform = transforms.ToTensor()\n",
    "train_set = datasets.MNIST(root=\"../data/MNIST\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(root=\"../data/MNIST\", download=True, train=False, transform=transform)\n",
    "\n",
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=16, persistent_workers=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=128, num_workers=16, persistent_workers=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1024, num_workers=16, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim=28*28, hidden_nodes_1=64, hidden_nodes_2=64, out_dim=4):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_nodes_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_nodes_1, hidden_nodes_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_nodes_2, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_dim=4, hidden_nodes_1=64, hidden_nodes_2=64, out_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_nodes_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_nodes_1, hidden_nodes_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_nodes_2, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)\n",
    "\n",
    "class LitAutoEncoder(LightningModule):\n",
    "    def __init__(self, encoder, decoder, lr=1e-5, example_input_array=None):\n",
    "        super().__init__()\n",
    "        self.example_input_array = example_input_array\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=[\"encoder\", \"decoder\"])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        loss = self._get_loss(batch)\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        loss = self._get_loss(batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        loss = self._get_loss(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.forward(x)\n",
    "\n",
    "    def _get_loss(self, batch):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708d722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder(\n",
    "    encoder=Encoder(\n",
    "        in_dim=28*28,\n",
    "        hidden_nodes_1=512,\n",
    "        hidden_nodes_2=256,\n",
    "        out_dim=100\n",
    "    ),\n",
    "    decoder=Decoder(\n",
    "        in_dim=100,\n",
    "        hidden_nodes_1=128,\n",
    "        hidden_nodes_2=256,\n",
    "        out_dim=28*28\n",
    "    ),\n",
    "    lr=1e-4,\n",
    "    example_input_array=torch.zeros(32, 1, 28*28)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff470c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger(\n",
    "    save_dir='logs',\n",
    "    name='mnist_test',\n",
    "    version=None,\n",
    "    prefix='test_'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(logger.log_dir, \"checkpoints\"),\n",
    "    filename=\"autoencoder-{epoch:02d}-{val_loss:.6f}\",\n",
    "    monitor=\"val_loss\",    \n",
    "    mode=\"min\",\n",
    "    save_top_k=3,     # keep ONLY the best\n",
    "    save_last=True    # ALSO save last.ckpt\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "model_summary_callback = ModelSummary(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be1ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    profiler = 'simple',\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, model_summary_callback],\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd61334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method test in module lightning.pytorch.trainer.trainer:\n",
      "\n",
      "test(\n",
      "    model: Optional[ForwardRef('pl.LightningModule')] = None,\n",
      "    dataloaders: Union[Any, lightning.pytorch.core.datamodule.LightningDataModule, NoneType] = None,\n",
      "    ckpt_path: Union[str, pathlib._local.Path, NoneType] = None,\n",
      "    verbose: bool = True,\n",
      "    datamodule: Optional[lightning.pytorch.core.datamodule.LightningDataModule] = None,\n",
      "    weights_only: Optional[bool] = None\n",
      ") -> list[collections.abc.Mapping[str, float]] method of lightning.pytorch.trainer.trainer.Trainer instance\n",
      "    Perform one evaluation epoch over the test set. It's separated from fit to make sure you never run on your\n",
      "    test set until you want to.\n",
      "\n",
      "    Args:\n",
      "        model: The model to test.\n",
      "\n",
      "        dataloaders: An iterable or collection of iterables specifying test samples.\n",
      "            Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\n",
      "            the :class:`~lightning.pytorch.core.hooks.DataHooks.test_dataloader` hook.\n",
      "\n",
      "        ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\n",
      "            to test. If ``None`` and the model instance was passed, use the current weights.\n",
      "            Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\n",
      "            if a checkpoint callback is configured.\n",
      "\n",
      "        verbose: If True, prints the test results.\n",
      "\n",
      "        datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\n",
      "            the :class:`~lightning.pytorch.core.hooks.DataHooks.test_dataloader` hook.\n",
      "\n",
      "        weights_only: Defaults to ``None``. If ``True``, restricts loading to ``state_dicts`` of plain\n",
      "            ``torch.Tensor`` and other primitive types. If loading a checkpoint from a trusted source that contains\n",
      "            an ``nn.Module``, use ``weights_only=False``. If loading checkpoint from an untrusted source, we\n",
      "            recommend using ``weights_only=True``. For more information, please refer to the\n",
      "            `PyTorch Developer Notes on Serialization Semantics <https://docs.pytorch.org/docs/main/notes/serialization.html#id3>`_.\n",
      "\n",
      "    For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\n",
      "\n",
      "    Returns:\n",
      "        List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks\n",
      "        like :meth:`~lightning.pytorch.LightningModule.test_step` etc.\n",
      "        The length of the list corresponds to the number of test dataloaders used.\n",
      "\n",
      "    Raises:\n",
      "        TypeError:\n",
      "            If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\n",
      "            If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\n",
      "\n",
      "        MisconfigurationException:\n",
      "            If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\n",
      "\n",
      "        RuntimeError:\n",
      "            If a compiled ``model`` is passed and the strategy is not supported.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(trainer.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc198f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "   | Name         | Type       | Params | Mode  | FLOPs  | In sizes     | Out sizes   \n",
      "--------------------------------------------------------------------------------------------\n",
      "0  | encoder      | Encoder    | 558 K  | train | 35.7 M | [32, 1, 784] | [32, 1, 100]\n",
      "1  | encoder.ff   | Sequential | 558 K  | train | 35.7 M | [32, 1, 784] | [32, 1, 100]\n",
      "2  | encoder.ff.0 | Linear     | 401 K  | train | 25.7 M | [32, 1, 784] | [32, 1, 512]\n",
      "3  | encoder.ff.1 | ReLU       | 0      | train | 0      | [32, 1, 512] | [32, 1, 512]\n",
      "4  | encoder.ff.2 | Linear     | 131 K  | train | 8.4 M  | [32, 1, 512] | [32, 1, 256]\n",
      "5  | encoder.ff.3 | ReLU       | 0      | train | 0      | [32, 1, 256] | [32, 1, 256]\n",
      "6  | encoder.ff.4 | Linear     | 25.7 K | train | 1.6 M  | [32, 1, 256] | [32, 1, 100]\n",
      "7  | decoder      | Decoder    | 247 K  | train | 15.8 M | [32, 1, 100] | [32, 1, 784]\n",
      "8  | decoder.ff   | Sequential | 247 K  | train | 15.8 M | [32, 1, 100] | [32, 1, 784]\n",
      "9  | decoder.ff.0 | Linear     | 12.9 K | train | 819 K  | [32, 1, 100] | [32, 1, 128]\n",
      "10 | decoder.ff.1 | ReLU       | 0      | train | 0      | [32, 1, 128] | [32, 1, 128]\n",
      "11 | decoder.ff.2 | Linear     | 33.0 K | train | 2.1 M  | [32, 1, 128] | [32, 1, 256]\n",
      "12 | decoder.ff.3 | ReLU       | 0      | train | 0      | [32, 1, 256] | [32, 1, 256]\n",
      "13 | decoder.ff.4 | Linear     | 201 K  | train | 12.8 M | [32, 1, 256] | [32, 1, 784]\n",
      "--------------------------------------------------------------------------------------------\n",
      "806 K     Trainable params\n",
      "0         Non-trainable params\n",
      "806 K     Total params\n",
      "3.226     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "51.5 M    Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/375 [00:00<?, ?it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 375/375 [00:04<00:00, 76.13it/s, v_num=1, val_loss=0.00617, train_loss=0.00616]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 375/375 [00:05<00:00, 73.91it/s, v_num=1, val_loss=0.00617, train_loss=0.00616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                               \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                \t|  -              \t|  1730200        \t|  543.24         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                   \t|  5.2558         \t|  100            \t|  525.58         \t|  96.749         \t|\n",
      "|  run_training_batch                                                                                                                                                   \t|  0.0078258      \t|  37500          \t|  293.47         \t|  54.022         \t|\n",
      "|  [LightningModule]LitAutoEncoder.optimizer_step                                                                                                                       \t|  0.0077077      \t|  37500          \t|  289.04         \t|  53.206         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                         \t|  0.0035905      \t|  37500          \t|  134.64         \t|  24.785         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                              \t|  0.002371       \t|  37500          \t|  88.911         \t|  16.367         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                         \t|  0.0023187      \t|  37500          \t|  86.951         \t|  16.006         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                       \t|  0.0028711      \t|  9402           \t|  26.994         \t|  4.9691         \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                    \t|  0.0027846      \t|  9402           \t|  26.181         \t|  4.8194         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                       \t|  0.00038973     \t|  46902          \t|  18.279         \t|  3.3648         \t|\n",
      "|  [LightningModule]LitAutoEncoder.transfer_batch_to_device                                                                                                             \t|  0.00032691     \t|  46903          \t|  15.333         \t|  2.8225         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.14753        \t|  100            \t|  14.753         \t|  2.7157         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                           \t|  0.00035602     \t|  37500          \t|  13.351         \t|  2.4576         \t|\n",
      "|  save_checkpoint                                                                                                                                                      \t|  0.064564       \t|  200            \t|  12.913         \t|  2.377          \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                           \t|  0.00092301     \t|  9402           \t|  8.6781         \t|  1.5975         \t|\n",
      "|  [LightningModule]LitAutoEncoder.optimizer_zero_grad                                                                                                                  \t|  0.00018279     \t|  37500          \t|  6.8548         \t|  1.2618         \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_gradient_clipping                                                                                                          \t|  2.8989e-05     \t|  37500          \t|  1.0871         \t|  0.20011        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  2.3287e-05     \t|  37500          \t|  0.87325        \t|  0.16075        \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_end                                                                                     \t|  0.0082222      \t|  100            \t|  0.82222        \t|  0.15135        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                  \t|  7.469e-05      \t|  9402           \t|  0.70223        \t|  0.12927        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                        \t|  0.0060622      \t|  101            \t|  0.61229        \t|  0.11271        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                          \t|  0.0035812      \t|  101            \t|  0.3617         \t|  0.066581       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                         \t|  0.0022815      \t|  100            \t|  0.22815        \t|  0.041998       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_zero_grad                                                                                    \t|  5.5686e-06     \t|  37500          \t|  0.20882        \t|  0.03844        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                       \t|  0.0019028      \t|  100            \t|  0.19028        \t|  0.035027       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_end                                                                                     \t|  4.8416e-06     \t|  37500          \t|  0.18156        \t|  0.033422       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_backward                                                                                     \t|  3.8258e-06     \t|  37500          \t|  0.14347        \t|  0.02641        \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_start                                                                                   \t|  3.5709e-06     \t|  37500          \t|  0.13391        \t|  0.02465        \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_batch_transfer                                                                                                             \t|  2.7141e-06     \t|  46903          \t|  0.1273         \t|  0.023434       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                  \t|  0.12568        \t|  1              \t|  0.12568        \t|  0.023134       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_after_backward                                                                                      \t|  3.2539e-06     \t|  37500          \t|  0.12202        \t|  0.022461       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                          \t|  2.5443e-06     \t|  37500          \t|  0.095413       \t|  0.017564       \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                             \t|  2.4543e-06     \t|  37500          \t|  0.092035       \t|  0.016942       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                   \t|  2.3571e-06     \t|  37500          \t|  0.088392       \t|  0.016271       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_after_batch_transfer                                                                                                              \t|  1.8825e-06     \t|  46903          \t|  0.088293       \t|  0.016253       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_optimizer_step                                                                               \t|  2.2435e-06     \t|  37500          \t|  0.084132       \t|  0.015487       \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                           \t|  2.2419e-06     \t|  37500          \t|  0.084072       \t|  0.015476       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_batch_end                                                                                                                   \t|  2.043e-06      \t|  37500          \t|  0.076614       \t|  0.014103       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                            \t|  2.0377e-06     \t|  37500          \t|  0.076415       \t|  0.014067       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  1.8887e-06     \t|  37500          \t|  0.070826       \t|  0.013038       \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                            \t|  1.8351e-06     \t|  37500          \t|  0.068815       \t|  0.012668       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                        \t|  1.8165e-06     \t|  37500          \t|  0.068117       \t|  0.012539       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                         \t|  1.8116e-06     \t|  37500          \t|  0.067935       \t|  0.012505       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  1.7984e-06     \t|  37500          \t|  0.067438       \t|  0.012414       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  1.786e-06      \t|  37500          \t|  0.066976       \t|  0.012329       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                       \t|  1.7701e-06     \t|  37500          \t|  0.06638        \t|  0.012219       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_zero_grad                                                                                                                  \t|  1.6817e-06     \t|  37500          \t|  0.063063       \t|  0.011609       \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                      \t|  1.67e-06       \t|  37500          \t|  0.062623       \t|  0.011528       \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                          \t|  1.5664e-06     \t|  37500          \t|  0.058741       \t|  0.010813       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  1.5566e-06     \t|  37500          \t|  0.058372       \t|  0.010745       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  1.5448e-06     \t|  37500          \t|  0.057928       \t|  0.010663       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_after_backward                                                                                                                    \t|  1.4489e-06     \t|  37500          \t|  0.054332       \t|  0.010001       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_end                                                                                \t|  5.7139e-06     \t|  9402           \t|  0.053722       \t|  0.0098892      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                  \t|  1.3981e-06     \t|  37500          \t|  0.052428       \t|  0.009651       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_batch_start                                                                                                                 \t|  1.3889e-06     \t|  37500          \t|  0.052082       \t|  0.0095873      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_backward                                                                                                                   \t|  1.3548e-06     \t|  37500          \t|  0.050803       \t|  0.0093519      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_optimizer_step                                                                                                             \t|  1.3099e-06     \t|  37500          \t|  0.049122       \t|  0.0090423      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  5.1248e-06     \t|  9402           \t|  0.048184       \t|  0.0088697      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_start                                                                              \t|  4.6422e-06     \t|  9402           \t|  0.043646       \t|  0.0080343      \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                       \t|  2.8294e-06     \t|  9402           \t|  0.026602       \t|  0.004897       \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                     \t|  2.7579e-06     \t|  9402           \t|  0.02593        \t|  0.0047731      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_batch_end                                                                                                              \t|  2.4597e-06     \t|  9402           \t|  0.023127       \t|  0.0042571      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  2.3018e-06     \t|  9402           \t|  0.021641       \t|  0.0039837      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_batch_start                                                                                                            \t|  2.1791e-06     \t|  9402           \t|  0.020488       \t|  0.0037715      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_zero_grad                                                                                                        \t|  0.00016955     \t|  100            \t|  0.016955       \t|  0.003121       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_eval                                                                                                             \t|  0.000111       \t|  101            \t|  0.011211       \t|  0.0020638      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  3.6683e-05     \t|  101            \t|  0.003705       \t|  0.00068202     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                      \t|  0.0029678      \t|  1              \t|  0.0029678      \t|  0.00054632     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                             \t|  0.0023286      \t|  1              \t|  0.0023286      \t|  0.00042864     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                               \t|  0.00090583     \t|  1              \t|  0.00090583     \t|  0.00016675     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_end                                                                                      \t|  6.5342e-06     \t|  101            \t|  0.00065995     \t|  0.00012148     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_save_checkpoint                                                                                     \t|  3.0016e-06     \t|  200            \t|  0.00060032     \t|  0.00011051     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_end                                                                                \t|  4.7537e-06     \t|  101            \t|  0.00048013     \t|  8.8382e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                            \t|  4.4056e-06     \t|  100            \t|  0.00044056     \t|  8.1098e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  4.2174e-06     \t|  101            \t|  0.00042596     \t|  7.8411e-05     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                            \t|  1.9049e-06     \t|  200            \t|  0.00038098     \t|  7.0131e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.00038042     \t|  1              \t|  0.00038042     \t|  7.0027e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_save_checkpoint                                                                                                                   \t|  1.8286e-06     \t|  200            \t|  0.00036572     \t|  6.7323e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_start                                                                                    \t|  3.4833e-06     \t|  101            \t|  0.00035181     \t|  6.4761e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_start                                                                                   \t|  3.03e-06       \t|  100            \t|  0.000303       \t|  5.5775e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_epoch_end                                                                                                                   \t|  2.8943e-06     \t|  100            \t|  0.00028943     \t|  5.3279e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_end                                                                                                                    \t|  2.8097e-06     \t|  101            \t|  0.00028378     \t|  5.2238e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                       \t|  2.7236e-06     \t|  101            \t|  0.00027509     \t|  5.0638e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_start                                                                                                                  \t|  2.6398e-06     \t|  101            \t|  0.00026662     \t|  4.908e-05      \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                             \t|  2.5362e-06     \t|  101            \t|  0.00025616     \t|  4.7154e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_start                                                                              \t|  2.399e-06      \t|  101            \t|  0.0002423      \t|  4.4603e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  2.3738e-06     \t|  100            \t|  0.00023738     \t|  4.3697e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                         \t|  1.0459e-06     \t|  200            \t|  0.00020917     \t|  3.8504e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  1.0338e-06     \t|  200            \t|  0.00020677     \t|  3.8061e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  2.0358e-06     \t|  101            \t|  0.00020562     \t|  3.785e-05      \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                     \t|  1.952e-06      \t|  101            \t|  0.00019715     \t|  3.6292e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_epoch_end                                                                                                              \t|  1.9054e-06     \t|  101            \t|  0.00019245     \t|  3.5426e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_optimizers                                                                                                                 \t|  0.00018674     \t|  1              \t|  0.00018674     \t|  3.4376e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                    \t|  1.8264e-06     \t|  101            \t|  0.00018446     \t|  3.3956e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                  \t|  1.7978e-06     \t|  101            \t|  0.00018158     \t|  3.3425e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  1.6536e-06     \t|  101            \t|  0.00016701     \t|  3.0743e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                     \t|  1.6186e-06     \t|  101            \t|  0.00016348     \t|  3.0094e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                   \t|  1.5876e-06     \t|  101            \t|  0.00016035     \t|  2.9517e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                           \t|  1.5158e-06     \t|  101            \t|  0.00015309     \t|  2.8181e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_epoch_start                                                                                                            \t|  1.458e-06      \t|  101            \t|  0.00014726     \t|  2.7107e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                          \t|  1.2829e-06     \t|  100            \t|  0.00012829     \t|  2.3615e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_epoch_start                                                                                                                 \t|  1.19e-06       \t|  100            \t|  0.000119       \t|  2.1906e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_start                                                                                         \t|  1.1316e-05     \t|  1              \t|  1.1316e-05     \t|  2.0831e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  1.0653e-05     \t|  1              \t|  1.0653e-05     \t|  1.961e-06      \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                        \t|  8.6059e-06     \t|  1              \t|  8.6059e-06     \t|  1.5842e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_end                                                                                             \t|  7.465e-06      \t|  1              \t|  7.465e-06      \t|  1.3742e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.setup                                                                                                  \t|  5.5539e-06     \t|  1              \t|  5.5539e-06     \t|  1.0224e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  4.5309e-06     \t|  1              \t|  4.5309e-06     \t|  8.3405e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.teardown                                                                                               \t|  3.9991e-06     \t|  1              \t|  3.9991e-06     \t|  7.3616e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_start                                                                                                                       \t|  3.9828e-06     \t|  1              \t|  3.9828e-06     \t|  7.3316e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                        \t|  3.7178e-06     \t|  1              \t|  3.7178e-06     \t|  6.8438e-07     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                      \t|  3.0887e-06     \t|  1              \t|  3.0887e-06     \t|  5.6857e-07     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                    \t|  3.0734e-06     \t|  1              \t|  3.0734e-06     \t|  5.6575e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                      \t|  2.6561e-06     \t|  1              \t|  2.6561e-06     \t|  4.8894e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_end                                                                                           \t|  2.6529e-06     \t|  1              \t|  2.6529e-06     \t|  4.8834e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_start                                                                                  \t|  2.5639e-06     \t|  1              \t|  2.5639e-06     \t|  4.7197e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                               \t|  2.326e-06      \t|  1              \t|  2.326e-06      \t|  4.2817e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_callbacks                                                                                                                  \t|  2.2138e-06     \t|  1              \t|  2.2138e-06     \t|  4.0751e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_start                                                                                           \t|  2.1686e-06     \t|  1              \t|  2.1686e-06     \t|  3.9919e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.teardown                                                                                                                             \t|  2.0829e-06     \t|  1              \t|  2.0829e-06     \t|  3.8342e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_end                                                                                    \t|  2.0391e-06     \t|  1              \t|  2.0391e-06     \t|  3.7536e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.setup                                                                                                                                \t|  1.9651e-06     \t|  1              \t|  1.9651e-06     \t|  3.6173e-07     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                         \t|  1.8324e-06     \t|  1              \t|  1.8324e-06     \t|  3.373e-07      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  1.7746e-06     \t|  1              \t|  1.7746e-06     \t|  3.2668e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  1.7337e-06     \t|  1              \t|  1.7337e-06     \t|  3.1913e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                   \t|  1.628e-06      \t|  1              \t|  1.628e-06      \t|  2.9967e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                 \t|  1.5581e-06     \t|  1              \t|  1.5581e-06     \t|  2.8682e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_fit_end                                                                                                                           \t|  1.5311e-06     \t|  1              \t|  1.5311e-06     \t|  2.8184e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  1.3052e-06     \t|  1              \t|  1.3052e-06     \t|  2.4027e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                \t|  1.2806e-06     \t|  1              \t|  1.2806e-06     \t|  2.3573e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_fit_start                                                                                                                         \t|  1.0291e-06     \t|  1              \t|  1.0291e-06     \t|  1.8944e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                  \t|  1.0272e-06     \t|  1              \t|  1.0272e-06     \t|  1.891e-07      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_end                                                                                                                         \t|  9.7323e-07     \t|  1              \t|  9.7323e-07     \t|  1.7915e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                           \t|  9.6625e-07     \t|  1              \t|  9.6625e-07     \t|  1.7787e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                         \t|  8.1677e-07     \t|  1              \t|  8.1677e-07     \t|  1.5035e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  7.8091e-07     \t|  1              \t|  7.8091e-07     \t|  1.4375e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  6.4913e-07     \t|  1              \t|  6.4913e-07     \t|  1.1949e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                          \t|  6.482e-07      \t|  1              \t|  6.482e-07      \t|  1.1932e-07     \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 149.54it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.006019039079546928\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST Profiler Report\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                               \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                \t|  -              \t|  1730394        \t|  544.47         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                   \t|  5.2558         \t|  100            \t|  525.58         \t|  96.53          \t|\n",
      "|  run_training_batch                                                                                                                                                   \t|  0.0078258      \t|  37500          \t|  293.47         \t|  53.899         \t|\n",
      "|  [LightningModule]LitAutoEncoder.optimizer_step                                                                                                                       \t|  0.0077077      \t|  37500          \t|  289.04         \t|  53.086         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                         \t|  0.0035905      \t|  37500          \t|  134.64         \t|  24.729         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                              \t|  0.002371       \t|  37500          \t|  88.911         \t|  16.33          \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                         \t|  0.0023187      \t|  37500          \t|  86.951         \t|  15.97          \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                       \t|  0.0028711      \t|  9402           \t|  26.994         \t|  4.9579         \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                    \t|  0.0027846      \t|  9402           \t|  26.181         \t|  4.8085         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                       \t|  0.0003897      \t|  46912          \t|  18.282         \t|  3.3577         \t|\n",
      "|  [LightningModule]LitAutoEncoder.transfer_batch_to_device                                                                                                             \t|  0.00032688     \t|  46913          \t|  15.335         \t|  2.8165         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.14753        \t|  100            \t|  14.753         \t|  2.7095         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                           \t|  0.00035602     \t|  37500          \t|  13.351         \t|  2.452          \t|\n",
      "|  save_checkpoint                                                                                                                                                      \t|  0.064564       \t|  200            \t|  12.913         \t|  2.3716         \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                           \t|  0.00092301     \t|  9402           \t|  8.6781         \t|  1.5939         \t|\n",
      "|  [LightningModule]LitAutoEncoder.optimizer_zero_grad                                                                                                                  \t|  0.00018279     \t|  37500          \t|  6.8548         \t|  1.259          \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_gradient_clipping                                                                                                          \t|  2.8989e-05     \t|  37500          \t|  1.0871         \t|  0.19966        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  2.3287e-05     \t|  37500          \t|  0.87325        \t|  0.16038        \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_end                                                                                     \t|  0.0082222      \t|  100            \t|  0.82222        \t|  0.15101        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                  \t|  7.469e-05      \t|  9402           \t|  0.70223        \t|  0.12897        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                        \t|  0.0060622      \t|  101            \t|  0.61229        \t|  0.11246        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                          \t|  0.0035812      \t|  101            \t|  0.3617         \t|  0.066431       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                         \t|  0.0022815      \t|  100            \t|  0.22815        \t|  0.041903       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_zero_grad                                                                                    \t|  5.5686e-06     \t|  37500          \t|  0.20882        \t|  0.038353       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                       \t|  0.0019028      \t|  100            \t|  0.19028        \t|  0.034947       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_end                                                                                     \t|  4.8416e-06     \t|  37500          \t|  0.18156        \t|  0.033346       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_backward                                                                                     \t|  3.8258e-06     \t|  37500          \t|  0.14347        \t|  0.02635        \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_start                                                                                   \t|  3.5709e-06     \t|  37500          \t|  0.13391        \t|  0.024594       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_batch_transfer                                                                                                             \t|  2.7142e-06     \t|  46913          \t|  0.12733        \t|  0.023386       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                  \t|  0.12568        \t|  1              \t|  0.12568        \t|  0.023082       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_after_backward                                                                                      \t|  3.2539e-06     \t|  37500          \t|  0.12202        \t|  0.022411       \t|\n",
      "|  [_EvaluationLoop].test_next                                                                                                                                          \t|  0.011889       \t|  10             \t|  0.11889        \t|  0.021837       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                          \t|  2.5443e-06     \t|  37500          \t|  0.095413       \t|  0.017524       \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                             \t|  2.4543e-06     \t|  37500          \t|  0.092035       \t|  0.016904       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                   \t|  2.3571e-06     \t|  37500          \t|  0.088392       \t|  0.016234       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_after_batch_transfer                                                                                                              \t|  1.8824e-06     \t|  46913          \t|  0.088311       \t|  0.01622        \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_optimizer_step                                                                               \t|  2.2435e-06     \t|  37500          \t|  0.084132       \t|  0.015452       \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                           \t|  2.2419e-06     \t|  37500          \t|  0.084072       \t|  0.015441       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_batch_end                                                                                                                   \t|  2.043e-06      \t|  37500          \t|  0.076614       \t|  0.014071       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                            \t|  2.0377e-06     \t|  37500          \t|  0.076415       \t|  0.014035       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  1.8887e-06     \t|  37500          \t|  0.070826       \t|  0.013008       \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                            \t|  1.8351e-06     \t|  37500          \t|  0.068815       \t|  0.012639       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                        \t|  1.8165e-06     \t|  37500          \t|  0.068117       \t|  0.012511       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                         \t|  1.8116e-06     \t|  37500          \t|  0.067935       \t|  0.012477       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  1.7984e-06     \t|  37500          \t|  0.067438       \t|  0.012386       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  1.786e-06      \t|  37500          \t|  0.066976       \t|  0.012301       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                       \t|  1.7701e-06     \t|  37500          \t|  0.06638        \t|  0.012192       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_zero_grad                                                                                                                  \t|  1.6817e-06     \t|  37500          \t|  0.063063       \t|  0.011582       \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                      \t|  1.67e-06       \t|  37500          \t|  0.062623       \t|  0.011502       \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                          \t|  1.5664e-06     \t|  37500          \t|  0.058741       \t|  0.010789       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  1.5566e-06     \t|  37500          \t|  0.058372       \t|  0.010721       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  1.5448e-06     \t|  37500          \t|  0.057928       \t|  0.010639       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_after_backward                                                                                                                    \t|  1.4489e-06     \t|  37500          \t|  0.054332       \t|  0.0099788      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_end                                                                                \t|  5.7139e-06     \t|  9402           \t|  0.053722       \t|  0.0098669      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                  \t|  1.3981e-06     \t|  37500          \t|  0.052428       \t|  0.0096292      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_batch_start                                                                                                                 \t|  1.3889e-06     \t|  37500          \t|  0.052082       \t|  0.0095656      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_backward                                                                                                                   \t|  1.3548e-06     \t|  37500          \t|  0.050803       \t|  0.0093308      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_optimizer_step                                                                                                             \t|  1.3099e-06     \t|  37500          \t|  0.049122       \t|  0.0090219      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  5.1248e-06     \t|  9402           \t|  0.048184       \t|  0.0088496      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_start                                                                              \t|  4.6422e-06     \t|  9402           \t|  0.043646       \t|  0.0080161      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.test_step                                                                                                                             \t|  0.0027523      \t|  10             \t|  0.027523       \t|  0.005055       \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                       \t|  2.8294e-06     \t|  9402           \t|  0.026602       \t|  0.0048859      \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                     \t|  2.7579e-06     \t|  9402           \t|  0.02593        \t|  0.0047624      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_batch_end                                                                                                              \t|  2.4597e-06     \t|  9402           \t|  0.023127       \t|  0.0042475      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  2.3018e-06     \t|  9402           \t|  0.021641       \t|  0.0039747      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_batch_start                                                                                                            \t|  2.1791e-06     \t|  9402           \t|  0.020488       \t|  0.003763       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_zero_grad                                                                                                        \t|  0.00016955     \t|  100            \t|  0.016955       \t|  0.003114       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_eval                                                                                                             \t|  0.000111       \t|  101            \t|  0.011211       \t|  0.0020591      \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_end                                                                                                                          \t|  0.0010021      \t|  10             \t|  0.010021       \t|  0.0018405      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  3.6683e-05     \t|  101            \t|  0.003705       \t|  0.00068047     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                      \t|  0.0029678      \t|  1              \t|  0.0029678      \t|  0.00054508     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_start                                                                                                                        \t|  0.00028472     \t|  10             \t|  0.0028472      \t|  0.00052293     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                             \t|  0.0023286      \t|  1              \t|  0.0023286      \t|  0.00042767     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_start                                                                                                                              \t|  0.0021415      \t|  1              \t|  0.0021415      \t|  0.00039332     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                               \t|  0.00090583     \t|  1              \t|  0.00090583     \t|  0.00016637     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_end                                                                                                                                \t|  0.00068608     \t|  1              \t|  0.00068608     \t|  0.00012601     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_end                                                                                      \t|  6.5342e-06     \t|  101            \t|  0.00065995     \t|  0.00012121     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_save_checkpoint                                                                                     \t|  3.0016e-06     \t|  200            \t|  0.00060032     \t|  0.00011026     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_end                                                                                \t|  4.7537e-06     \t|  101            \t|  0.00048013     \t|  8.8182e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.00022726     \t|  2              \t|  0.00045452     \t|  8.3478e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                            \t|  4.4056e-06     \t|  100            \t|  0.00044056     \t|  8.0915e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  4.2174e-06     \t|  101            \t|  0.00042596     \t|  7.8233e-05     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                            \t|  1.9049e-06     \t|  200            \t|  0.00038098     \t|  6.9972e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_save_checkpoint                                                                                                                   \t|  1.8286e-06     \t|  200            \t|  0.00036572     \t|  6.717e-05      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_start                                                                                    \t|  3.4833e-06     \t|  101            \t|  0.00035181     \t|  6.4615e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_start                                                                                   \t|  3.03e-06       \t|  100            \t|  0.000303       \t|  5.5649e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_epoch_end                                                                                                                   \t|  2.8943e-06     \t|  100            \t|  0.00028943     \t|  5.3158e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_end                                                                                                                    \t|  2.8097e-06     \t|  101            \t|  0.00028378     \t|  5.212e-05      \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                       \t|  2.7236e-06     \t|  101            \t|  0.00027509     \t|  5.0523e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_start                                                                                                                  \t|  2.6398e-06     \t|  101            \t|  0.00026662     \t|  4.8969e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                             \t|  2.5362e-06     \t|  101            \t|  0.00025616     \t|  4.7047e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_start                                                                              \t|  2.399e-06      \t|  101            \t|  0.0002423      \t|  4.4502e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  2.3738e-06     \t|  100            \t|  0.00023738     \t|  4.3598e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                         \t|  1.0459e-06     \t|  200            \t|  0.00020917     \t|  3.8417e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  1.0338e-06     \t|  200            \t|  0.00020677     \t|  3.7975e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  2.0358e-06     \t|  101            \t|  0.00020562     \t|  3.7764e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                     \t|  1.952e-06      \t|  101            \t|  0.00019715     \t|  3.621e-05      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_epoch_end                                                                                                              \t|  1.9054e-06     \t|  101            \t|  0.00019245     \t|  3.5346e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_optimizers                                                                                                                 \t|  0.00018674     \t|  1              \t|  0.00018674     \t|  3.4298e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                    \t|  1.8264e-06     \t|  101            \t|  0.00018446     \t|  3.3879e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                  \t|  1.7978e-06     \t|  101            \t|  0.00018158     \t|  3.3349e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_model_eval                                                                                                                   \t|  0.00017601     \t|  1              \t|  0.00017601     \t|  3.2327e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  1.6536e-06     \t|  101            \t|  0.00016701     \t|  3.0674e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                     \t|  1.6186e-06     \t|  101            \t|  0.00016348     \t|  3.0026e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                   \t|  1.5876e-06     \t|  101            \t|  0.00016035     \t|  2.9451e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                           \t|  1.5158e-06     \t|  101            \t|  0.00015309     \t|  2.8118e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_epoch_start                                                                                                            \t|  1.458e-06      \t|  101            \t|  0.00014726     \t|  2.7046e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                          \t|  1.2829e-06     \t|  100            \t|  0.00012829     \t|  2.3562e-05     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_epoch_start                                                                                                                 \t|  1.19e-06       \t|  100            \t|  0.000119       \t|  2.1856e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_test_batch_start                                                                                    \t|  6.5664e-06     \t|  10             \t|  6.5664e-05     \t|  1.206e-05      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_test_batch_end                                                                                      \t|  4.7788e-06     \t|  10             \t|  4.7788e-05     \t|  8.7769e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_end        \t|  3.5067e-06     \t|  10             \t|  3.5067e-05     \t|  6.4406e-06     \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_end                                                                                                                             \t|  2.5294e-06     \t|  10             \t|  2.5294e-05     \t|  4.6456e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_start      \t|  2.1711e-06     \t|  10             \t|  2.1711e-05     \t|  3.9876e-06     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_batch_end                                                                                                                    \t|  2.1352e-06     \t|  10             \t|  2.1352e-05     \t|  3.9215e-06     \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_start                                                                                                                           \t|  1.9124e-06     \t|  10             \t|  1.9124e-05     \t|  3.5124e-06     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_batch_start                                                                                                                  \t|  1.5341e-06     \t|  10             \t|  1.5341e-05     \t|  2.8175e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.teardown                                                                                               \t|  6.1055e-06     \t|  2              \t|  1.2211e-05     \t|  2.2427e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_start                                                                                         \t|  1.1316e-05     \t|  1              \t|  1.1316e-05     \t|  2.0783e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  1.0653e-05     \t|  1              \t|  1.0653e-05     \t|  1.9566e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.setup                                                                                                  \t|  4.861e-06      \t|  2              \t|  9.7221e-06     \t|  1.7856e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                        \t|  8.6059e-06     \t|  1              \t|  8.6059e-06     \t|  1.5806e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_end                                                                                             \t|  7.465e-06      \t|  1              \t|  7.465e-06      \t|  1.3711e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                      \t|  2.7663e-06     \t|  2              \t|  5.5325e-06     \t|  1.0161e-06     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                      \t|  2.4869e-06     \t|  2              \t|  4.9737e-06     \t|  9.1349e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  4.5309e-06     \t|  1              \t|  4.5309e-06     \t|  8.3216e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.teardown                                                                                                                             \t|  2.2319e-06     \t|  2              \t|  4.4638e-06     \t|  8.1984e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_callbacks                                                                                                                  \t|  2.2138e-06     \t|  2              \t|  4.4275e-06     \t|  8.1317e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_test_start                                                                                          \t|  4.3274e-06     \t|  1              \t|  4.3274e-06     \t|  7.9479e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_test_epoch_start                                                                                    \t|  4.0922e-06     \t|  1              \t|  4.0922e-06     \t|  7.516e-07      \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_start                                                                                                                       \t|  3.9828e-06     \t|  1              \t|  3.9828e-06     \t|  7.315e-07      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_test_epoch_end                                                                                      \t|  3.9744e-06     \t|  1              \t|  3.9744e-06     \t|  7.2996e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                        \t|  3.7178e-06     \t|  1              \t|  3.7178e-06     \t|  6.8283e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_test_end                                                                                            \t|  3.7169e-06     \t|  1              \t|  3.7169e-06     \t|  6.8266e-07     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                         \t|  1.7441e-06     \t|  2              \t|  3.4883e-06     \t|  6.4067e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.setup                                                                                                                                \t|  1.7355e-06     \t|  2              \t|  3.471e-06      \t|  6.3751e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_start                                                                                                                         \t|  3.41e-06       \t|  1              \t|  3.41e-06       \t|  6.263e-07      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  1.6952e-06     \t|  2              \t|  3.3905e-06     \t|  6.2271e-07     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                    \t|  3.0734e-06     \t|  1              \t|  3.0734e-06     \t|  5.6447e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                   \t|  1.505e-06      \t|  2              \t|  3.01e-06       \t|  5.5284e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_end                                                                                           \t|  2.6529e-06     \t|  1              \t|  2.6529e-06     \t|  4.8724e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_start                                                                                  \t|  2.5639e-06     \t|  1              \t|  2.5639e-06     \t|  4.709e-07      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_end              \t|  2.4452e-06     \t|  1              \t|  2.4452e-06     \t|  4.4909e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                               \t|  2.326e-06      \t|  1              \t|  2.326e-06      \t|  4.272e-07      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_start            \t|  2.2631e-06     \t|  1              \t|  2.2631e-06     \t|  4.1565e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_start                                                                                           \t|  2.1686e-06     \t|  1              \t|  2.1686e-06     \t|  3.9829e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_end                                                                                    \t|  2.0391e-06     \t|  1              \t|  2.0391e-06     \t|  3.7451e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_end                                                                                                                             \t|  1.9493e-06     \t|  1              \t|  1.9493e-06     \t|  3.5801e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_end                                                                                                                                   \t|  1.7821e-06     \t|  1              \t|  1.7821e-06     \t|  3.2731e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  1.7337e-06     \t|  1              \t|  1.7337e-06     \t|  3.1841e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_end                                                                                                                          \t|  1.567e-06      \t|  1              \t|  1.567e-06      \t|  2.8779e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                 \t|  1.5581e-06     \t|  1              \t|  1.5581e-06     \t|  2.8617e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_epoch_end                                                                                                                    \t|  1.532e-06      \t|  1              \t|  1.532e-06      \t|  2.8138e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_fit_end                                                                                                                           \t|  1.5311e-06     \t|  1              \t|  1.5311e-06     \t|  2.8121e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_end        \t|  1.4668e-06     \t|  1              \t|  1.4668e-06     \t|  2.694e-07      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_end                                                                                                                           \t|  1.3057e-06     \t|  1              \t|  1.3057e-06     \t|  2.3981e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  1.3052e-06     \t|  1              \t|  1.3052e-06     \t|  2.3973e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_start                                                                                                                        \t|  1.2834e-06     \t|  1              \t|  1.2834e-06     \t|  2.3571e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                \t|  1.2806e-06     \t|  1              \t|  1.2806e-06     \t|  2.3519e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_start                                                                                                                                 \t|  1.2703e-06     \t|  1              \t|  1.2703e-06     \t|  2.3331e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_end                                                                                                                          \t|  1.2568e-06     \t|  1              \t|  1.2568e-06     \t|  2.3083e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_fit_start                                                                                                                         \t|  1.0291e-06     \t|  1              \t|  1.0291e-06     \t|  1.8901e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                  \t|  1.0272e-06     \t|  1              \t|  1.0272e-06     \t|  1.8867e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_end                                                                                                                         \t|  9.7323e-07     \t|  1              \t|  9.7323e-07     \t|  1.7875e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                           \t|  9.6625e-07     \t|  1              \t|  9.6625e-07     \t|  1.7746e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_start      \t|  8.8383e-07     \t|  1              \t|  8.8383e-07     \t|  1.6233e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                         \t|  8.1677e-07     \t|  1              \t|  8.1677e-07     \t|  1.5001e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  7.8091e-07     \t|  1              \t|  7.8091e-07     \t|  1.4343e-07     \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_start                                                                                                                           \t|  7.0874e-07     \t|  1              \t|  7.0874e-07     \t|  1.3017e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  6.4913e-07     \t|  1              \t|  6.4913e-07     \t|  1.1922e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                          \t|  6.482e-07      \t|  1              \t|  6.482e-07      \t|  1.1905e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_start                                                                                                                        \t|  6.4401e-07     \t|  1              \t|  6.4401e-07     \t|  1.1828e-07     \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_test_epoch_start                                                                                                                  \t|  5.8115e-07     \t|  1              \t|  5.8115e-07     \t|  1.0674e-07     \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.006019039079546928}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b27c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping was not triggered.\n"
     ]
    }
   ],
   "source": [
    "# Access human-readable message\n",
    "if early_stop_callback.stopping_reason_message:\n",
    "    print(f\"Details: {early_stop_callback.stopping_reason_message}\")\n",
    "else:\n",
    "    print(\"Early stopping was not triggered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac86cd79",
   "metadata": {},
   "source": [
    "### Load a checkpoint and predict\n",
    "The easiest way to use a model for predictions is to load the weights using load_from_checkpoint found in the LightningModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5980f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = LitAutoEncoder.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    encoder=model.encoder,\n",
    "    decoder=model.decoder\n",
    ")\n",
    "model_new.eval()\n",
    "x = torch.randn(128, 1, 28*28)\n",
    "x = x.to(model_new.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat = model_new(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854b658",
   "metadata": {},
   "source": [
    "### Predict step with your LightningModule\n",
    "Loading a checkpoint and predicting still leaves you with a lot of boilerplate around the predict epoch. The predict step in the LightningModule removes this boilerplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd533e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(LightningModule):\n",
    "    def __init__(self, encoder, decoder, lr=1e-5, example_input_array=None):\n",
    "        super().__init__()\n",
    "        self.example_input_array = example_input_array\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=[\"encoder\", \"decoder\"])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        loss = self._get_loss(batch)\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        loss = self._get_loss(batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        loss = self._get_loss(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.forward(x)\n",
    "\n",
    "    def _get_loss(self, batch):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ddaa380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:941\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    940\u001b[39m \u001b[38;5;28mself\u001b[39m.predicting = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:990\u001b[39m, in \u001b[36mTrainer._predict_impl\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    986\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    987\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    988\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    989\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    993\u001b[39m \u001b[38;5;28mself\u001b[39m.predicting = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1079\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path, weights_only)\u001b[39m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1076\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1077\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1078\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1082\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1084\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1118\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._evaluation_loop.run()\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m   1120\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/prediction_loop.py:125\u001b[39m, in \u001b[36m_PredictionLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/prediction_loop.py:255\u001b[39m, in \u001b[36m_PredictionLoop._predict_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# configure step_kwargs\u001b[39;00m\n\u001b[32m    250\u001b[39m step_args = (\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, \u001b[33m\"\u001b[39m\u001b[33mpredict_step\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    254\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m predictions = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredict_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    257\u001b[39m     \u001b[38;5;28mself\u001b[39m._warning_cache.warn(\u001b[33m\"\u001b[39m\u001b[33mpredict returned None if it was on purpose, ignore this warning...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:329\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    332\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py:438\u001b[39m, in \u001b[36mStrategy.predict_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mpredict_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/core/module.py:968\u001b[39m, in \u001b[36mLightningModule.predict_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m \u001b[38;5;66;03m# For backwards compatibility\u001b[39;00m\n\u001b[32m    967\u001b[39m batch = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m, args[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m968\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mLitAutoEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     x_hat = \u001b[38;5;28mself\u001b[39m.decoder(z)\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x_hat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: linear(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "trainer.predict(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "669671d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMCdropoutModel(LightningModule):\n",
    "    def __init__(self, model, mc_iteration):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.mc_iteration = mc_iteration\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # enable Monte Carlo Dropout\n",
    "        self.dropout.train()\n",
    "\n",
    "        # take average of `self.mc_iteration` iterations\n",
    "        pred = [self.dropout(self.model(x)).unsqueeze(0) for _ in range(self.mc_iteration)]\n",
    "        pred = torch.vstack(pred).mean(dim=0)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
