{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ef7f83",
   "metadata": {},
   "source": [
    "# Level 2: Add a validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997048a",
   "metadata": {},
   "source": [
    "## Validate and test a model (basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf822e",
   "metadata": {},
   "source": [
    "### Find the train and test splits\n",
    "Datasets come with two splits. Refer to the dataset documentation to find the train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90fe464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load data sets\n",
    "transform = transforms.ToTensor()\n",
    "train_set = datasets.MNIST(root=\"MNIST\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(root=\"MNIST\", download=True, train=False, transform=transform)\n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3fef9",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad698a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d28d6",
   "metadata": {},
   "source": [
    "### Define the test loop\n",
    "To add a test loop, implement the test_step method of the LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797a1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cf7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True, num_workers=16)\n",
    "test_loader = DataLoader(test_set, batch_size=1024, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec6e7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:00<00:00, 136.10it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:00<00:00, 130.72it/s, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 159.14it/s]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "        test_loss           0.06368378549814224\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.06368378549814224}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# initialize the Trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=1\n",
    ")\n",
    "\n",
    "#torch.set_float32_matmul_precision('medium' | 'high')\n",
    "\n",
    "\n",
    "# train model\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)\n",
    "\n",
    "# test the model\n",
    "trainer.test(model=autoencoder, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf499d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1\n",
    ")\n",
    "print(trainer.strategy.root_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6695aad",
   "metadata": {},
   "source": [
    "### Add a validation loop\n",
    "Split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d423e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(train_set, [train_set_size, valid_set_size], generator=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972960f",
   "metadata": {},
   "source": [
    "### Define the validation loop\n",
    "To add a validation loop, implement the validation_step method of the LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921cb03",
   "metadata": {},
   "source": [
    "### Train with the validation loop\n",
    "To run the validation loop, pass in the validation set to .fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0f3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 155.22it/s, v_num=1]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 154.06it/s, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=16)\n",
    "valid_loader = DataLoader(valid_set, batch_size=128, shuffle=False, num_workers=16)\n",
    "model = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# train with both splits\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdea922",
   "metadata": {},
   "source": [
    "## Saving and loading checkpoints (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9adf7f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# saves checkpoints to 'some/path/checkpoints/'\n",
    "trainer = L.Trainer(default_root_dir=\"some/path/\", logger=False, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb75e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# checkpoints will be saved to 'logs/my_experiment/version_0/checkpoints/'\n",
    "# NOT to 'some/path/checkpoints/'\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=\"some/path/\",  # This will be ignored for checkpoints!\n",
    "    logger=CSVLogger(\"logs\", \"my_experiment\"),\n",
    "    max_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdedc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 152.68it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 151.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=16)\n",
    "valid_loader = DataLoader(valid_set, batch_size=128, shuffle=False, num_workers=16)\n",
    "model = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# train with both splits\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ede8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# explicitly set checkpoint directory\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"my/custom/checkpoint/path/\")\n",
    "trainer = L.Trainer(\n",
    "    logger=CSVLogger(\"logs\", \"my_experiment\"),\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ad2ffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 149.71it/s, v_num=0]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 148.48it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# train with both splits\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c810779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0db5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder.load_from_checkpoint(\"/storage3/DSIP/rriva/tutorials/pl_tutorial/basic/my/custom/checkpoint/path/epoch=4-step=1875.ckpt\",\n",
    "    encoder=Encoder(),\n",
    "    decoder=Decoder()\n",
    ")\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "# sample input\n",
    "x = torch.randn(1, 28 * 28).to(trainer.strategy.root_device)\n",
    "\n",
    "# predict with the model\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c04ef",
   "metadata": {},
   "source": [
    "### Save hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3f63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lightning import LightningModule\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f980ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets\n",
    "transform = transforms.ToTensor()\n",
    "train_set = datasets.MNIST(root=\"MNIST\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(root=\"MNIST\", download=True, train=False, transform=transform)\n",
    "\n",
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=16)\n",
    "valid_loader = DataLoader(valid_set, batch_size=128, num_workers=16)\n",
    "test_loader = DataLoader(test_set, batch_size=1024, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b550dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "class LitAutoEncoder(LightningModule):\n",
    "    def __init__(self, encoder, decoder, lr=1e-5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=[\"encoder\", \"decoder\"])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708d722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder(\n",
    "    encoder=Encoder(),\n",
    "    decoder=Decoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be1ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# explicitly set checkpoint directory\n",
    "logger = CSVLogger(\"logs\", \"experiment_with_hparams\")\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=os.path.join(logger.log_dir,'checkpoints'))\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc198f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 142.60it/s, v_num=3, val_loss=0.078] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 141.61it/s, v_num=3, val_loss=0.078]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a327a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/storage3/DSIP/rriva/tutorials/pl_tutorial/basic/logs/experiment_with_hparams/version_2/checkpoints/epoch=4-step=1875.ckpt'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607ab32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "model = LitAutoEncoder.load_from_checkpoint(checkpoint_path,\n",
    "    encoder=Encoder(),\n",
    "    decoder=Decoder(),\n",
    ")\n",
    "print(model.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53e2eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "model = LitAutoEncoder.load_from_checkpoint(checkpoint_path,\n",
    "    encoder=Encoder(),\n",
    "    decoder=Decoder(),\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print(model.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98a5bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "encoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n",
    "decoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"decoder.\")}\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ef027",
   "metadata": {},
   "source": [
    "### Disable checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85949c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(enable_checkpointing=False, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92806b58",
   "metadata": {},
   "source": [
    "### Resume training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8520c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e36e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /storage3/DSIP/rriva/tutorials/pl_tutorial/basic/logs/experiment_with_hparams/version_3/checkpoints exists and is not empty.\n",
      "Restoring states from the checkpoint path at /storage3/DSIP/rriva/tutorials/pl_tutorial/basic/logs/experiment_with_hparams/version_2/checkpoints/epoch=4-step=1875.ckpt\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:566: The dirpath has changed from '/storage3/DSIP/rriva/tutorials/pl_tutorial/basic/logs/experiment_with_hparams/version_2/checkpoints' to '/storage3/DSIP/rriva/tutorials/pl_tutorial/basic/logs/experiment_with_hparams/version_3/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n",
      "Restored all states from the checkpoint at /storage3/DSIP/rriva/tutorials/pl_tutorial/basic/logs/experiment_with_hparams/version_2/checkpoints/epoch=4-step=1875.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 139.67it/s, v_num=3, val_loss=0.0633]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 138.72it/s, v_num=3, val_loss=0.0633]\n"
     ]
    }
   ],
   "source": [
    "model = LitAutoEncoder(\n",
    "    encoder=Encoder(),\n",
    "    decoder=Decoder()\n",
    ")\n",
    "# automatically restores model, epoch, step, LR schedulers, etc...\n",
    "trainer.fit(model, train_loader, valid_loader, ckpt_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edf2b2",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2daba626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0707a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train | 0    \n",
      "1 | decoder | Decoder | 51.2 K | train | 0    \n",
      "----------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:02<00:00, 181.39it/s, v_num=3, val_loss=0.0471]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage3/DSIP/rriva/tutorials/pl_tutorial/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "trainer.fit(model,train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694c171",
   "metadata": {},
   "source": [
    "https://lightning.ai/docs/pytorch/stable/common/early_stopping.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bf20c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
